## Sourcing the data into R
datatr <- read.csv("E:/Documents/Coursera/Machine Learning/Week 4 Programming Assignment/pml-training.csv",na.strings=c("NA","#DIV/0!",""))
testingdata <- read.csv("E:/Documents/Coursera/Machine Learning/Week 4 Programming Assignment/pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
 
## Loading the required libraries
library(caret)
library(ggplot2)
library(randomForest)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(RMySQL)
library(pROC)
library(foreach)
library(doParallel)
library(gbm)

## Removing Question Marks in the data
datatr[datatr=="?"] <- NA

## Removing NearZero Covariates / Predictors
nzv1 <- nearZeroVar(datatr,saveMetrics=TRUE)
nzv1 
datatr <- subset(datatr,select=-c(kurtosis_yaw_belt,skewness_yaw_belt,amplitude_yaw_belt,kurtosis_yaw_dumbbell,skewness_yaw_dumbbell,amplitude_yaw_dumbbell,kurtosis_yaw_forearm,skewness_yaw_forearm,amplitude_yaw_forearm))

## Replacing all punctuation marks in all columns by "_"
colnames(datatr) <- gsub(pattern="[[:punct:]]",x=colnames(datatr))

## Converting the class of "classe" covriate into numeric
datatr$classe <- as.numeric(datatr$classe)

## Creating Dummy Variables by converting all Factor Variables
dmy <- dummyVars("~.",data=datatr)

## Creating New Dataframe with Dummy Variables
datatr1 <- data.frame(predict(dmy,newdata=datatr))
dim(datatr1)

## Removing NearZero Covariates / Predictors in new dataframe
nzv2 <- nearZeroVar(datatr1,saveMetrics=TRUE)
nzv2

## Converting the class of "classe" covriate into factor
datatr1$classe <- as.factor(datatr1$classe)
cols <- c("classe")
datatr1[,cols] <- data.frame(apply(datatr1[cols], 2, as.factor))
levels(datatr1$classe)  <- c("A","B","C","D","E")

## Removing NA & Missing Values
datatr1[is.na(datatr1)] <- 0

## Creating Training & Test Data Sets
set.seed(6)
inTrain <- createDataPartition(y=datatr1$classe,p=0.7,list=FALSE)
training <- datatr1[inTrain,]
testing <- datatr1[-inTrain,]

## Computing & Checking whether Area Under Curve > 0.5
lm1 <- lm(classe~.,data=training)
newdata <- data.frame(testing)
pred <- predict(lm1,newdata)
print(auc(testing$classe,pred))

outcomeName <- 'classe'
predictorNames <- setdiff(names(training),outcomeName)

## Performing Bagging
cl <- makeCluster(2)
registerDoParallel(cl)
length_divisor <- 20
predictions <- foreach(m=1:400,.combine=cbind)%dopar%{
      # Using sample function without seed
      sampleRows <- sample(nrow(training),size=floor((nrow(training)/length_divisor)))
      fit <- lm(classe~.,data=training[sampleRows,])
      predictions <- data.frame(predict(object=fit,testing[,predictorNames],se.fit=TRUE)[[1]])
}
stopCluster(cl)
library(pROC)
auc(testing[,outcomeName],rowMeans(predictions))

## Prediction Using Random Forest Method
fitRf <- train(classe ~ ., data=training, method="rf")
predRf <- predict(fitRf, testing)
c1 <- confusionMatrix(predRf, testing$classe)$overall[1]
